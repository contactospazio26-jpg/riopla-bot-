import express, { Request, Response } from "express";
import bodyParser from "body-parser";
import OpenAI from "openai";

const app = express();
app.use(bodyParser.json());

// Cliente OpenAI con la API key desde Vercel
const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

console.log("ğŸš€ Servidor iniciado en Vercel, escuchando /webhook");

app.post("/webhook", async (req: Request, res: Response) => {
  try {
    console.log("ğŸ‘‰ EntrÃ³ al endpoint /webhook");

    const userMessage = req.body?.message || "Hola";
    console.log("ğŸ“© Mensaje recibido:", userMessage);

    // Llamada al modelo GPT
    const completion = await client.chat.completions.create({
      model: "gpt-4o-mini", // podÃ©s cambiar a gpt-4o o gpt-3.5-turbo si querÃ©s probar
      messages: [
        { role: "system", content: "Sos Agus, promotora de bienestar de SkinCare ğŸ’–. RespondÃ© cÃ¡lida y profesionalmente." },
        { role: "user", content: userMessage }
      ],
      max_tokens: 100,
      temperature: 0.8
    });

    console.log("ğŸ“ Respuesta completa de OpenAI:", JSON.stringify(completion, null, 2));

    const reply = completion.choices[0]?.message?.content || "Disculpa, no entendÃ­.";
    console.log("âœ… Texto final enviado al cliente:", reply);

    res.json({ reply });
  } catch (error) {
    console.error("âŒ Error en webhook:", error);
    res.status(500).json({ reply: "OcurriÃ³ un error, intenta mÃ¡s tarde ğŸ’”" });
  }
});

export default app;
